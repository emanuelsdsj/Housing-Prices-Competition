{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imputer, grid, robust, cross\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Machine Learning\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path_test = 'Data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv('Data/train.csv' , index_col= 0)\n",
    "test_data = pd.read_csv(path_test  , index_col= 0)\n",
    "\n",
    "train_data = train_data[train_data.GrLivArea < 4500]\n",
    "\n",
    "label = train_data[['SalePrice']]\n",
    "train_data.drop('SalePrice' , axis = 1 , inplace=True)\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking and Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide in categorical columns and numerical columns\n",
    "numerical_col = []\n",
    "cat_col = []\n",
    "for x in train_data.columns:\n",
    "    if train_data[x].dtype == 'object':\n",
    "        cat_col.append(x)\n",
    "        print(x+': ' + str(len(train_data[x].unique())))\n",
    "    else:\n",
    "        numerical_col.append(x)\n",
    "        \n",
    "print('CAT col \\n', cat_col)\n",
    "print('Numerical col\\n')\n",
    "print(numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking skew\n",
    "numerical = train_data.select_dtypes(exclude='object').copy()\n",
    "\n",
    "fig = plt.figure(figsize=(12,18))\n",
    "for i in range(len(numerical.columns)):\n",
    "    fig.add_subplot(9,4,i+1)\n",
    "    sns.distplot(numerical.iloc[:,i].dropna())\n",
    "    plt.xlabel(numerical.columns[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking corr and choosing columns to be removed\n",
    "\n",
    "transformed_corr = train_data.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(transformed_corr)\n",
    "\n",
    "# Highly-correlated:\n",
    "# GarageCars and GarageArea\n",
    "# YearBuilt and GarageYrBlt\n",
    "# GrLivArea_log1p and TotRmsAbvGrd\n",
    "\n",
    "columns_highCorr_drop = ['GarageCars', 'GarageYrBlt', 'TotRmsAbvGrd', '2ndFlrSF', '1stFlrSF']\n",
    "\n",
    "# Drop Highly_correlated\n",
    "train_data = train_data.drop(columns_highCorr_drop, axis=1)\n",
    "test_data = test_data.drop(columns_highCorr_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical_col)\n",
    "numerical_col.remove('TotRmsAbvGrd')\n",
    "numerical_col.remove('GarageYrBlt')\n",
    "numerical_col.remove('GarageCars')\n",
    "numerical_col.remove('2ndFlrSF')\n",
    "numerical_col.remove('1stFlrSF')\n",
    "print(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skew data reduce\n",
    "len_train = train_data.shape[0]\n",
    "\n",
    "houses=pd.concat([train_data,test_data], sort=False)\n",
    "skew=houses.select_dtypes(include=['int','float']).apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skew_df=pd.DataFrame({'Skew':skew})\n",
    "skewed_df=skew_df[(skew_df['Skew']>0.5)|(skew_df['Skew']<-0.5)]\n",
    "\n",
    "train_data=houses[:len_train]\n",
    "test_data=houses[len_train:]\n",
    "\n",
    "# Reduce skew in target - Log\n",
    "label = np.log(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning numerical columns from train_data and test_data\n",
    "imputer = Imputer(missing_values='NaN' , strategy='mean' , axis = 0)\n",
    "imputer = imputer.fit(train_data[numerical_col])\n",
    "train_num = imputer.transform(train_data[numerical_col])\n",
    "\n",
    "test_num = imputer.transform(test_data[numerical_col])\n",
    "print(train_num.shape)\n",
    "print(test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning categorical columns from train_data and test_data\n",
    "\n",
    "train_cat = train_data[cat_col]\n",
    "test_cat = test_data[cat_col]\n",
    "\n",
    "dropp = ['MiscFeature' , 'PoolQC' , 'Fence' ,'Alley' ]\n",
    "train_cat.drop(columns=dropp , axis=1, inplace=True)\n",
    "train_cat = train_cat.astype('category')\n",
    "test_cat.drop(columns=dropp , axis=1, inplace=True)\n",
    "test_cat = test_cat.astype('category')\n",
    "\n",
    "# Fill null values with the most frequent attribute\n",
    "most_freq = {}\n",
    "for col in train_cat.columns:\n",
    "    p = train_cat[col].mode()[0]\n",
    "    train_cat[col].fillna(p, inplace=True)\n",
    "    most_freq[col] = p\n",
    "\n",
    "for col in train_cat.columns:\n",
    "    test_cat[col].fillna(most_freq[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to dataframe\n",
    "\n",
    "train_num = pd.DataFrame(train_num)\n",
    "train_num.head(2)\n",
    "test_num = pd.DataFrame(test_num)\n",
    "test_num.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categoricals values\n",
    "for col in train_cat:\n",
    "    train_cat[col] = train_cat[col].cat.codes\n",
    "for col in test_cat:\n",
    "    test_cat[col] = test_cat[col].cat.codes\n",
    "train_cat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same index for numerical and categorical dataframes\n",
    "train_num.index = train_cat.index\n",
    "test_num.index = test_cat.index\n",
    "\n",
    "# Get dummies for categorical columns\n",
    "train_cat = pd.get_dummies(train_cat)\n",
    "test_cat = pd.get_dummies(test_cat)\n",
    "\n",
    "# Join the 2 datas into one\n",
    "train_ = train_num.join(train_cat)\n",
    "test_ = test_num.join(test_cat)\n",
    "\n",
    "# Scaling the data\n",
    "scalar = RobustScaler()\n",
    "train_ = scalar.fit_transform(train_)\n",
    "test_ = scalar.transform(test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning and Hyper-Parameters Tuning (TO BE CONTINUED...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lightgbm = lgb.LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=8,\n",
    "                                       learning_rate=0.03, \n",
    "                                       n_estimators=4000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )\n",
    "scores = cross_val_score(lightgbm, train_, label, cv=5).mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso(alpha =0.001, random_state=1)\n",
    "scores = cross_val_score(lasso_model, train_, label, cv=5).mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=0.002, random_state=5)\n",
    "scores = cross_val_score(ridge_model, train_, label, cv=5).mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGBRegressor - Hyperparameter Tuning\n",
    "\n",
    "# xgbRegressor = XGBRegressor()\n",
    "# n_estimators = range(70, 100)\n",
    "# learning_rate = np.arange(0.4, 0.7, 0.1)\n",
    "\n",
    "# ## Search grid for optimal parameters\n",
    "# param_grid = {\"n_estimators\" : n_estimators}\n",
    "\n",
    "# model_xgb = GridSearchCV(xgbRegressor, param_grid = param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "# model_xgb.fit(train_,label)\n",
    "\n",
    "# # Best score\n",
    "# print(model_xgb.best_score_)\n",
    "\n",
    "# #best estimator\n",
    "# model_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor(n_estimators=4000, learning_rate=0.05)\n",
    "scores = cross_val_score(xgb_model, train_, label, cv=5).mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove log from prediction\n",
    "def inv_y(transformed_y):\n",
    "    return np.exp(transformed_y)\n",
    "\n",
    "# Choose model\n",
    "lasso_model.fit(train_, label)\n",
    "pre = lasso_model.predict(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': pd.read_csv(path_test).Id,\n",
    "                       'SalePrice': inv_y(pre)})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
